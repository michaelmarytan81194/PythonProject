{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "021821a8",
   "metadata": {},
   "source": [
    "<h3> 1. Retrieve the Data Source <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "622a975b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-01-10 00:52:27--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2707 (2,6K) [application/zip]\n",
      "Saving to: 'source.zip'\n",
      "\n",
      "     0K ..                                                    100%  506M=0s\n",
      "\n",
      "2024-01-10 00:52:29 (506 MB/s) - 'source.zip' saved [2707/2707]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5284c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip the zip file\n",
    "import zipfile\n",
    "with zipfile.ZipFile('source.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf3022f-4699-465c-8500-da3196e7f489",
   "metadata": {},
   "source": [
    "<h3> 2. Import necessary libraries <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f3b3a3-3fef-4920-af94-955dffdddb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import pandas as pd \n",
    "import xml.etree.ElementTree as ET \n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3df91d-1c37-44a1-ae89-4bc6b9edd22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare variables that state file name:\n",
    "log_file = \"log_file.txt\" \n",
    "target_file = \"transformed_data.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbdb811-62a2-4bea-b6a5-940356aa8ba8",
   "metadata": {},
   "source": [
    "<h3>3. Write functions for Extract stage <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6644158-953a-46f1-8eca-75b4807165c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CSV\n",
    "def extract_from_csv (input_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f5408d-3207-4bc9-bd50-394d37d514ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSON\n",
    "def extract_from_json (input_file):\n",
    "    df = pd.read_json(input_file, lines = True) #Notice how json file is oschestrated as below, in turn, we need to add arg lines = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9920c01a-960c-458f-85d0-c6219c30cdaa",
   "metadata": {},
   "source": [
    "<img src=\"jsonsample.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18806f2-2a65-4551-8533-48657b180d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XML\n",
    "def extract_from_xml (input_file):\n",
    "    dataframe = pd.DataFrame (columns=[\"name\", \"height\", \"weight\"]) #blueprint the columns for DF\n",
    "    tree= ET.parse(input_file) #turn input_file as xml to an instance of ET\n",
    "    data = tree.getroot() #get into data ticket\n",
    "    for person in data:\n",
    "        name = person.find(\"name\").text \n",
    "        height = float(person.find(\"height\").text) \n",
    "        weight = float(person.find(\"weight\").text) \n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\": height, \"weight\":weight}])], ignore_index=True) #need to be the same name from dataframe which was declared below\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e026554e-84c0-4aeb-a61b-e5ddf9f7cb67",
   "metadata": {},
   "source": [
    "<img src=\"xmlsample.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9164b9cb-083c-4bac-a673-8389dc2f67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract all:\n",
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns =[\"name\", \"height\", \"weight\"])\n",
    "    for csvfile in glob.glob(\"*.csv\"):\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index = True)\n",
    "    for jsonfile in glob.glob(\"*.json\"):\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index = True)\n",
    "    for xmlfile in glob.glob(\"*.xml\"):\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index = True)\n",
    "    #after extract data from all kinds of files \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b131ead-ff2e-4339-8fc3-028b9489d32b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     65.78\n",
       "1     71.52\n",
       "2     69.40\n",
       "3     68.22\n",
       "4     67.79\n",
       "5     65.78\n",
       "6     71.52\n",
       "7     69.40\n",
       "8     68.22\n",
       "9     67.79\n",
       "10    65.78\n",
       "11    71.52\n",
       "12    69.40\n",
       "13    68.22\n",
       "14    67.79\n",
       "15    67.90\n",
       "16    66.78\n",
       "17    66.49\n",
       "18    67.62\n",
       "19    67.90\n",
       "20    66.78\n",
       "21    66.49\n",
       "22    67.62\n",
       "23    67.90\n",
       "24    66.78\n",
       "25    66.49\n",
       "26    67.62\n",
       "Name: height, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test how data is extracted\n",
    "test_extracted = extract()\n",
    "test_extracted['height'] #type: pandas.core.series.Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511a1ceb-57fb-4410-a451-836a57f663a5",
   "metadata": {},
   "source": [
    "<h3>4. Transform function <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f757559-5407-4961-ae74-4bc5442d12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform (data):\n",
    "    data['height'] = round(data.height *0.0254, 2) #data.height is also pandas.core.series.Series\n",
    "    data['weight'] = round(data.weight * 0.45359237, 2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10827397-e5c3-4fb4-b96e-62f7e1b01879",
   "metadata": {},
   "source": [
    "<h3> 5. Load function <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e86013a-f266-40c1-8b01-abe5f624b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data (target_file, transformed_data):\n",
    "    transformed_data.to_csv(target_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99996fdb-f05f-41fb-8091-ef1fd5ffaf29",
   "metadata": {},
   "source": [
    "<h3>6. Log function <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d52f6ba-e40c-41f8-971e-73aa4052dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress (message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S'\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(log_file, 'a') as file:\n",
    "        file.write ('At' + timestamp + ',' + message + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a70308e-bab2-4e8e-ae7b-dadfd39b0546",
   "metadata": {},
   "source": [
    "<h3> Test <>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50e557d6-2db1-4acc-8d4b-bbd94eb4da46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Data\n",
      "     name  height  weight\n",
      "0    alex    1.67   51.25\n",
      "1    ajay    1.82   61.91\n",
      "2   alice    1.76   69.41\n",
      "3    ravi    1.73   64.56\n",
      "4     joe    1.72   65.45\n",
      "5    alex    1.67   51.25\n",
      "6    ajay    1.82   61.91\n",
      "7   alice    1.76   69.41\n",
      "8    ravi    1.73   64.56\n",
      "9     joe    1.72   65.45\n",
      "10   alex    1.67   51.25\n",
      "11   ajay    1.82   61.91\n",
      "12  alice    1.76   69.41\n",
      "13   ravi    1.73   64.56\n",
      "14    joe    1.72   65.45\n",
      "15  simon    1.72   50.97\n",
      "16  jacob    1.70   54.73\n",
      "17  cindy    1.69   57.81\n",
      "18   ivan    1.72   51.77\n",
      "19  simon    1.72   50.97\n",
      "20  jacob    1.70   54.73\n",
      "21  cindy    1.69   57.81\n",
      "22   ivan    1.72   51.77\n",
      "23  simon    1.72   50.97\n",
      "24  jacob    1.70   54.73\n",
      "25  cindy    1.69   57.81\n",
      "26   ivan    1.72   51.77\n"
     ]
    }
   ],
   "source": [
    "# Log the initialization of the ETL process \n",
    "log_progress(\"ETL Job Started\") \n",
    " \n",
    "# Log the beginning of the Extraction process \n",
    "log_progress(\"Extract phase Started\") \n",
    "extracted_data = extract() \n",
    " \n",
    "# Log the completion of the Extraction process \n",
    "log_progress(\"Extract phase Ended\") \n",
    " \n",
    "# Log the beginning of the Transformation process \n",
    "log_progress(\"Transform phase Started\") \n",
    "transformed_data = transform(extracted_data) \n",
    "print(\"Transformed Data\") \n",
    "print(transformed_data) \n",
    " \n",
    "# Log the completion of the Transformation process \n",
    "log_progress(\"Transform phase Ended\") \n",
    " \n",
    "# Log the beginning of the Loading process \n",
    "log_progress(\"Load phase Started\") \n",
    "load_data(target_file,transformed_data) \n",
    " \n",
    "# Log the completion of the Loading process \n",
    "log_progress(\"Load phase Ended\") \n",
    " \n",
    "# Log the completion of the ETL process \n",
    "log_progress(\"ETL Job Ended\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f3f19-2fab-441b-930a-89541ef5b15c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
